# Streamlit App on Variational AutoEncoders

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-Deep_Learning-red.svg)](https://pytorch.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Web_App-ff4b4b.svg)](https://streamlit.io/)

Ce projet implÃ©mente diffÃ©rentes variantes d'Autoencodeurs Variationnels (VAEs) avec une interface utilisateur Streamlit permettant de dÃ©couvrir les VAEs en modifiant facilement les hyperparamÃ¨tres.

![App](https://img.shields.io/badge/-Streamlit-FF4B4B?style=flat&logo=streamlit&logoColor=white) 


## ğŸ“‹ Table des MatiÃ¨res

- [Introduction](#-introduction)
- [ModÃ¨les ImplÃ©mentÃ©s](#-modÃ¨les-implÃ©mentÃ©s)
- [RÃ©sultats](#-rÃ©sultats)
- [Installation](#-installation-avec-conda)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [Aspects Techniques](#-aspects-techniques)
- [Contributions](#-contributions)
- [RÃ©fÃ©rences](#-rÃ©fÃ©rences)

## ğŸ” Introduction

Un Variational Autoencoder (VAE) est un modÃ¨le gÃ©nÃ©ratif, c'est-Ã -dire qu'il permet de crÃ©er des images, du texte, de la musique, etc. Nous nous concentrerons uniquement sur la gÃ©nÃ©ration d'images, bien que les VAEs aient d'autres applications.

Les VAEs sont dÃ©rivÃ©s des auto-encodeurs, qui compressent des images pour les reprÃ©senter dans un espace de plus basse dimension : c'est le rÃ´le de l'encodeur. Ensuite, cette reprÃ©sentation latente est dÃ©compressÃ©e pour reconstituer l'image originale : c'est le rÃ´le du dÃ©codeur. Les auto-encodeurs sont utilisÃ©s quotidiennement pour envoyer des images et du son, avec pour objectif de rÃ©cupÃ©rer exactement ce qui a Ã©tÃ© envoyÃ©.

C'est ici que les VAEs se distinguent. Contrairement aux auto-encodeurs classiques, les VAEs ne sont pas dÃ©terministes. Ils permettent, Ã  partir d'une mÃªme reprÃ©sentation latente, de gÃ©nÃ©rer des images variÃ©es. L'encodeur ne fournit plus une reprÃ©sentation latente fixe, mais une distribution probabiliste de cette reprÃ©sentation.

## ğŸ§  ModÃ¨les ImplÃ©mentÃ©s

### VAE original
- VAE avec encodeur et dÃ©codeur gaussien
- ImplÃ©mentation basÃ©e sur l'article ["Auto-Encoding Variational Bayes"](https://arxiv.org/abs/1312.6114)

### Î²-VAE 
- Introduit un poids Î² dans la fonction de perte pour ajuster l'importance relative des deux termes
- BasÃ© sur l'article ["beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework"](https://openreview.net/forum?id=Sy2fzU9gl)

### Ïƒ-VAE
- Calcule analytiquement la variance des donnÃ©es Ïƒ et l'utilise dans la perte de reconstruction, qui est cette fois-ci une log-vraisemblance
- ImplÃ©mentation selon l'article ["Simple and Effective VAE Training with Calibrated Decoders"](https://orybkin.github.io/sigma-vae/)

![Chronologie des VAEs](img/frise.png)

## ğŸ’¥ RÃ©sultats

Pour avoir une idÃ©e des images que vous pouvez obtenir voici les rÃ©sutats d'un comparatif publiÃ© par Oleh Rybkin dans ["Simple and Effective VAE Training with Calibrated Decoders"](https://arxiv.org/pdf/2006.13202).

![Performances en gÃ©nÃ©ration des VAEs](img/vae_results.png)

## ğŸ’» Installation (avec conda)

```bash 
# Cloner le repository
git clone https://github.com/grAmine03/Master-2-Variational-Auto-Encoder
cd VAEs

# CrÃ©er et activer un environnement virtuel (optionnel)
conda create --name nom_de_l_environnement
conda activate nom_de_l_environnement

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸš€ Utilisation

Pour lancer l'application Streamlit:

```bash
streamlit run app.py
```

L'application s'ouvrira dans votre navigateur et vous pourrez en lire davantage sur les VAEs et explorer les 3 architectures implÃ©mentÃ©es.

## ğŸ“ Structure du Projet

```
VAEs/
â”œâ”€â”€ app.py                  # Application Streamlit
â”œâ”€â”€ requirements.txt        # DÃ©pendances du projet
â”œâ”€â”€ bvae.py                 # ImplÃ©mentation de BetaVAE
â”œâ”€â”€ svae.py                 # ImplÃ©mentation de SigmaVAE
â”œâ”€â”€ train.py                # Module pour l'entraÃ®nement
â”œâ”€â”€ utils.py                # Module pour rÃ©cuperer les donnÃ©es et enregistrer les modÃ¨les
â”œâ”€â”€ viz.py                  # Module pour les visualisations et les figures
â”œâ”€â”€ models/                 # ModÃ¨les et pertes enregistrer en .pth
â”œâ”€â”€ img/                    # Images pour l'application
â”œâ”€â”€ docs/                   # Documentation Sphinx
â”œâ”€â”€ Readme.md
```

## ğŸ”§ Aspects Techniques

### Import des donnÃ©es

Les donnÃ©es MNIST et CIFAR-10 sont tÃ©lÃ©chargÃ©es directement vers un dossier `data/` depuis le module `torchvision.datasets`. Avant de les utilisÃ©es dans nos modÃ¨les, les donnÃ©es sont standardisÃ©es.

### Architecture des modÃ¨les

Les modÃ¨les sont construits comme des classe hÃ©ritant de `nn.Module`. Ils contiennent plusieurs mÃ©thodes : 
- encode
- reparametrize
- decode
- forward
- loss_function
- sample 

Le VAE original est un BetaVAE avec `beta = 1`

### EntraÃ®nement

L'entraÃ®nement utilise une fonction de perte composÃ© d'un perte de reconstruction et d'une KL-divergence. La perte de reconstruction est une erreur quadratique (MSE et L1 error) ou bien une log-vraissemblance (gaussienne et laplacienne) pour SigmaVAE.

Le tout est optimisÃ© avec Adam pour un learning_rate optimisÃ© Ã  `1e-3`.

## Documentation avec Sphinx

Ce projet utilise Sphinx pour gÃ©nÃ©rer une documentation complÃ¨te et navigable. Voici comment configurer, crÃ©er et compiler la documentation.

### Installation de Sphinx

Pour installer Sphinx et les extensions nÃ©cessaires, exÃ©cutez :

```bash
pip install sphinx sphinx-rtd-theme autodoc numpydoc
```

### Structure de la documentation

La documentation est organisÃ©e dans le dossier `docs/` avec la structure suivante :

```
docs/
â”œâ”€â”€ source/
â”‚   â”œâ”€â”€ _static/
â”‚   â”œâ”€â”€ _templates/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ tutorials/
â”‚   â”œâ”€â”€ conf.py
â”‚   â”œâ”€â”€ index.rst
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Makefile
â””â”€â”€ make.bat
```

### GÃ©nÃ©ration de la documentation

Pour gÃ©nÃ©rer la documentation automatiquement :

```bash
cd docs
make html
```

Vous trouverez ensuite la documentation HTML dans `docs/build/html/`.

## ğŸ¤ Contributions

Les contributions sont les bienvenues! Pour contribuer:
1. Forkez le repository
2. CrÃ©ez une branche pour votre fonctionnalitÃ© (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Committez vos changements (`git commit -m 'Ajout d'une nouvelle fonctionnalitÃ©'`)
4. Poussez vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrez une Pull Request

## ğŸ“š RÃ©fÃ©rences

- [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)
- [beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework](https://openreview.net/forum?id=Sy2fzU9gl)
- [Simple and Effective VAE Training with Calibrated Decoders](https://orybkin.github.io/sigma-vae/)


